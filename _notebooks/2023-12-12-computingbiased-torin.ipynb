{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hack #1: \n",
    "Which of the following scenarios is an example of computing bias?\n",
    "\n",
    "A. An email filtering system accurately categorizes emails into spam and non-spam based on a diverse set of features, minimizing false positives and false negatives. <br>\n",
    "B. A navigation app provides real-time traffic updates and alternate routes to users, considering various factors such as traffic volume, road closures, and weather conditions. <br>\n",
    "C. An image recognition algorithm identifies objects in photographs with high accuracy, regardless of the gender, ethnicity, or age of the individuals depicted.<br>\n",
    "D. An automated hiring system consistently favors candidates from specific educational institutions and backgrounds, resulting in the exclusion of qualified applicants from diverse backgrounds.\n",
    "\n",
    "\n",
    "- The correct answer would be D. An automated hiring system consistently favors candidates from specific educational institutions and backgrounds, resulting in the exclusion of qualified applicants from diverse backgrounds.\n",
    "\n",
    "\n",
    "\n",
    "## Popcorn Hack #2:\n",
    "An online example of computing bias is when an HP computer’s facial recognition system couldn’t track the face of someone with darker skin. Why is this and what type of bias is it? Do you think it was intentional or unintentional?\n",
    "\n",
    "- This is an example of bias in facial recognition systems. The reason why this happens is because the training data used to build the facial recognition system was not diverse enough. This is an example of unintentional bias.\n",
    "\n",
    "\n",
    "## Popcorn Hack #3:\n",
    "\n",
    "- What is another scenario of data collection in everyday applications and situations?\n",
    "\n",
    "- Another scenario of data collection is when you use a fitness tracker to track your steps and heart rate. The fitness tracker collects data on your physical activity and heart rate throughout the day. This data can be used to provide insights and recommendations for improving your health and fitness. However, it is important to consider the privacy implications of sharing this data with third parties and to ensure that the data is being used in a responsible and ethical manner.\n",
    "\n",
    "\n",
    "\n",
    "## Homework:\n",
    "Problem: Biased Predictive Policing Algorithm: A city implements a predictive policing algorithm to allocate law enforcement resources more efficiently. \n",
    "However, concerns arise as community members and activists notice that the algorithm appears to disproportionately target certain neighborhoods, leading to over-policing and potential violations of civil rights.\n",
    "Provide a solution to how this situation can be resolved, and how the computing bias can be removed. Explain which method of mitigation you will use and how it works. \n",
    "\n",
    "- Solution: One way to address the issue of biased predictive policing algorithms is to use a fairness-aware machine learning approach. This involves modifying the algorithm to explicitly consider fairness criteria during the training and decision-making process."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
